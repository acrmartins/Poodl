# Modifications to the Paper: Ideologically Motivated Biases in a Multiple Issues Opinion Model

- Reviewer 2 wrote: "Are opinions in the range [0,1]? They should state that."
  - Its stated at the beginning, second paragraph, of section 2;

- Reviewer 2 asked " Why do stubborn agents have sigma=1e-20?"
  - This is an implementation detail. We modified the fourth paragraph of section
   3 so that its clear that what we're modeling is a sigma close to 0.

- Reviewer 2 said: "They should explain the concept of uncertainty and
  estimation. What does uncertainty mean? Why do agents have to estimate
  opinions? Don't they know their own opinions? Or is there an observation error
  when looking at the opinion of the interacting partner? Are there empirical
  evidence of the Bayesian approach or statistical inference in opinion
  dynamics? What are the sociological fundamentals of mechanisms of the model?"
  "They should explain the Bayesian rule in words, or more intuitively."

  - We have added a paragraph at the beginning of section 2 to state the
   framework we're using. We also indicated previous works that go deeper into
   these details. We believe it answers these questions and going further is
   beyond the scope of the paper.


- Review 3 wrote: " I found the paper lacking in empirical grounding. In terms
  of the micro-underpinnings of the model, I was expecting to see much more
  references to empirical work justifying the notion that opinion-distance is a
  relevant factor in opinion updating processes; and the notion that
  opinion-distance on other (more or less related) opinions plays a role, too
  (see previous point). Without such empirical evidence, statements such as "how
  much each agent trusts another agent should be a function of the distance
  between their opinions on the subject they are debating" sound a bit
  unfounded."
      - We have modified the first paragraph of section 1 to indicate the
   relevant literature about geometric models. It is not in the scope of the
   article to belabor a literature that is well known and widely used.

- Reviewer 2: "It is not clear to me how simulations were done. "..one sampling
of 70,000 times.." means 70,000 independent realizations of the dynamics?"
    - We answered that by modifying the second paragraph of section 3. "Times"
   is equal to quasi-random "draws" following saltelli's sampling (one of the
   paper' bibliographic references).

- Reviewer 2: " was the distribution of Fig. 1 done over many different runs of
the model? If that is the case, then it is hard to see whether there is
consensus or not in individual realizations. The should add a plot (or perhaps
an inset) showing the mean opinion of each agent in an single realization. What
are the parameter values sigma, n and p of Fig. 1?"
        - We have modified the paragraphs that explain Fig. 1 so that its clear
          we're investing the behavior of the model over many parameterizations.
          We've identified and pointed out the difference between initial and
          final state of the model both in the plot and in paragraphs explaining
          it. Plots of individual runs are depicted throughout the paper so it
          doesn't make sense to add another one here.

- Reviewer 2: "They also mention that sigma plays the role of
the threshold in Bounded confidence models (BCM). However, in page 4 it is
mentioned that Deltaij also plays the role of the threshold in BCM. However,
sigma and Deltaij seem to be independent variables. They should clarify that."
    - We have modified the first paragraph of the last section to fix that.


- Reviewer 3: "Likewise, I was expecting to see more reference to macro-level
  empirical work, which could either help justify the assumptions embedded in
  the model proposed by the authors, or be used as a validation-benchmark for
  the aggregate levels outcomes generated by the model. Without such empirical
  reference, claims made e.g. in the first phrases in the conclusions section
  feel unwarranted or at least as lacking empirical grounding. And then
  ultimately, one has to resort to much weaker claims such as the ones made in
  the abstract (where the use of the word 'might' gives away that in fact, we
  really do not know for sure if this is how things play out in real life)."

   - He also talks about salience. We've added a paragraph to the conclusion
     reinforcing what is the scope of the paper. Empirical
     calibration/validation and many other extensions, including salience, were
     imagined. The model, however, already had many interesting results and
     adding more extensions would make the paper decentered and harder to
     interpret/understand.
